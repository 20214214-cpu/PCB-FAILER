digraph {
	graph [size="113.85,113.85"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	3127754461808 [label="
 (1, 2)" fillcolor=darkolivegreen1]
	3127656284112 -> 3127754461728 [dir=none]
	3127754461728 [label="mat1
 (1, 512)" fillcolor=orange]
	3127656284112 -> 3127668454688 [dir=none]
	3127668454688 [label="mat2
 (512, 2)" fillcolor=orange]
	3127656284112 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 512)
mat1_sym_strides:       (512, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (512, 2)
mat2_sym_strides:       (1, 512)"]
	3127668548576 -> 3127656284112
	3127668064032 [label="fc.bias
 (2)" fillcolor=lightblue]
	3127668064032 -> 3127668548576
	3127668548576 [label=AccumulateGrad]
	3127170086608 -> 3127656284112
	3127170086608 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 512, 1, 1)"]
	3127718943024 -> 3127170086608
	3127718943024 [label="MeanBackward1
----------------------------------------
dim           : (4294967295, 4294967294)
keepdim       :                     True
self_sym_numel:                    25088
self_sym_sizes:           (1, 512, 7, 7)"]
	3127656167312 -> 3127718943024
	3127656167312 -> 3127754463088 [dir=none]
	3127754463088 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	3127656167312 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127718531936 -> 3127656167312
	3127718531936 [label="AddBackward0
------------
alpha: 1"]
	3127718532608 -> 3127718531936
	3127718532608 -> 3127754461648 [dir=none]
	3127754461648 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	3127718532608 -> 3127754463248 [dir=none]
	3127754463248 [label="result1
 (0)" fillcolor=orange]
	3127718532608 -> 3127754463408 [dir=none]
	3127754463408 [label="result2
 (0)" fillcolor=orange]
	3127718532608 -> 3127667800448 [dir=none]
	3127667800448 [label="running_mean
 (512)" fillcolor=orange]
	3127718532608 -> 3127667800848 [dir=none]
	3127667800848 [label="running_var
 (512)" fillcolor=orange]
	3127718532608 -> 3127667800608 [dir=none]
	3127667800608 [label="weight
 (512)" fillcolor=orange]
	3127718532608 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127718533232 -> 3127718532608
	3127718533232 -> 3127754461408 [dir=none]
	3127754461408 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	3127718533232 -> 3127667800688 [dir=none]
	3127667800688 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	3127718533232 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127666194032 -> 3127718533232
	3127666194032 -> 3127754463728 [dir=none]
	3127754463728 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	3127666194032 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127718471536 -> 3127666194032
	3127718471536 -> 3127754461568 [dir=none]
	3127754461568 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	3127718471536 -> 3127754464048 [dir=none]
	3127754464048 [label="result1
 (0)" fillcolor=orange]
	3127718471536 -> 3127754463888 [dir=none]
	3127754463888 [label="result2
 (0)" fillcolor=orange]
	3127718471536 -> 3127667799808 [dir=none]
	3127667799808 [label="running_mean
 (512)" fillcolor=orange]
	3127718471536 -> 3127667800208 [dir=none]
	3127667800208 [label="running_var
 (512)" fillcolor=orange]
	3127718471536 -> 3127667799968 [dir=none]
	3127667799968 [label="weight
 (512)" fillcolor=orange]
	3127718471536 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127718476432 -> 3127718471536
	3127718476432 -> 3127754461328 [dir=none]
	3127754461328 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	3127718476432 -> 3127667800048 [dir=none]
	3127667800048 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	3127718476432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127718539568 -> 3127718476432
	3127718539568 -> 3127754463648 [dir=none]
	3127754463648 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	3127718539568 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127719322448 -> 3127718539568
	3127719322448 [label="AddBackward0
------------
alpha: 1"]
	3127719329168 -> 3127719322448
	3127719329168 -> 3127754461248 [dir=none]
	3127754461248 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	3127719329168 -> 3127754463808 [dir=none]
	3127754463808 [label="result1
 (0)" fillcolor=orange]
	3127719329168 -> 3127754464608 [dir=none]
	3127754464608 [label="result2
 (0)" fillcolor=orange]
	3127719329168 -> 3127667799168 [dir=none]
	3127667799168 [label="running_mean
 (512)" fillcolor=orange]
	3127719329168 -> 3127667799568 [dir=none]
	3127667799568 [label="running_var
 (512)" fillcolor=orange]
	3127719329168 -> 3127667799328 [dir=none]
	3127667799328 [label="weight
 (512)" fillcolor=orange]
	3127719329168 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127719329024 -> 3127719329168
	3127719329024 -> 3127754461168 [dir=none]
	3127754461168 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	3127719329024 -> 3127667799408 [dir=none]
	3127667799408 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	3127719329024 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127719329264 -> 3127719329024
	3127719329264 -> 3127754464848 [dir=none]
	3127754464848 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	3127719329264 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127719322976 -> 3127719329264
	3127719322976 -> 3127754461088 [dir=none]
	3127754461088 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	3127719322976 -> 3127754465088 [dir=none]
	3127754465088 [label="result1
 (0)" fillcolor=orange]
	3127719322976 -> 3127754464928 [dir=none]
	3127754464928 [label="result2
 (0)" fillcolor=orange]
	3127719322976 -> 3127667798528 [dir=none]
	3127667798528 [label="running_mean
 (512)" fillcolor=orange]
	3127719322976 -> 3127667798928 [dir=none]
	3127667798928 [label="running_var
 (512)" fillcolor=orange]
	3127719322976 -> 3127667798688 [dir=none]
	3127667798688 [label="weight
 (512)" fillcolor=orange]
	3127719322976 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127719324032 -> 3127719322976
	3127719324032 -> 3127754461008 [dir=none]
	3127754461008 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127719324032 -> 3127667798768 [dir=none]
	3127667798768 [label="weight
 (512, 256, 3, 3)" fillcolor=orange]
	3127719324032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3127667691568 -> 3127719324032
	3127667691568 -> 3127754465168 [dir=none]
	3127754465168 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	3127667691568 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127667694016 -> 3127667691568
	3127667694016 [label="AddBackward0
------------
alpha: 1"]
	3127667697328 -> 3127667694016
	3127667697328 -> 3127754460928 [dir=none]
	3127754460928 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127667697328 -> 3127754465648 [dir=none]
	3127754465648 [label="result1
 (0)" fillcolor=orange]
	3127667697328 -> 3127754465568 [dir=none]
	3127754465568 [label="result2
 (0)" fillcolor=orange]
	3127667697328 -> 3127667797248 [dir=none]
	3127667797248 [label="running_mean
 (256)" fillcolor=orange]
	3127667697328 -> 3127667797648 [dir=none]
	3127667797648 [label="running_var
 (256)" fillcolor=orange]
	3127667697328 -> 3127667797408 [dir=none]
	3127667797408 [label="weight
 (256)" fillcolor=orange]
	3127667697328 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127667692432 -> 3127667697328
	3127667692432 -> 3127754460688 [dir=none]
	3127754460688 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127667692432 -> 3127667797488 [dir=none]
	3127667797488 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3127667692432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127667688880 -> 3127667692432
	3127667688880 -> 3127754465728 [dir=none]
	3127754465728 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	3127667688880 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802202912 -> 3127667688880
	3127802202912 -> 3127754460848 [dir=none]
	3127754460848 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127802202912 -> 3127754466128 [dir=none]
	3127754466128 [label="result1
 (0)" fillcolor=orange]
	3127802202912 -> 3127754466048 [dir=none]
	3127754466048 [label="result2
 (0)" fillcolor=orange]
	3127802202912 -> 3127667796608 [dir=none]
	3127667796608 [label="running_mean
 (256)" fillcolor=orange]
	3127802202912 -> 3127667797008 [dir=none]
	3127667797008 [label="running_var
 (256)" fillcolor=orange]
	3127802202912 -> 3127667796768 [dir=none]
	3127667796768 [label="weight
 (256)" fillcolor=orange]
	3127802202912 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802201520 -> 3127802202912
	3127802201520 -> 3127754460608 [dir=none]
	3127754460608 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127802201520 -> 3127667796848 [dir=none]
	3127667796848 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3127802201520 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127667690272 -> 3127802201520
	3127667690272 -> 3127754466208 [dir=none]
	3127754466208 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	3127667690272 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802203248 -> 3127667690272
	3127802203248 [label="AddBackward0
------------
alpha: 1"]
	3127802203056 -> 3127802203248
	3127802203056 -> 3127754460528 [dir=none]
	3127754460528 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127802203056 -> 3127754466688 [dir=none]
	3127754466688 [label="result1
 (0)" fillcolor=orange]
	3127802203056 -> 3127754466608 [dir=none]
	3127754466608 [label="result2
 (0)" fillcolor=orange]
	3127802203056 -> 3127667795968 [dir=none]
	3127667795968 [label="running_mean
 (256)" fillcolor=orange]
	3127802203056 -> 3127667796368 [dir=none]
	3127667796368 [label="running_var
 (256)" fillcolor=orange]
	3127802203056 -> 3127667796128 [dir=none]
	3127667796128 [label="weight
 (256)" fillcolor=orange]
	3127802203056 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802203008 -> 3127802203056
	3127802203008 -> 3127754460448 [dir=none]
	3127754460448 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127802203008 -> 3127667796208 [dir=none]
	3127667796208 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	3127802203008 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127802203296 -> 3127802203008
	3127802203296 -> 3127754466768 [dir=none]
	3127754466768 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	3127802203296 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802203728 -> 3127802203296
	3127802203728 -> 3127754460368 [dir=none]
	3127754460368 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127802203728 -> 3127754467168 [dir=none]
	3127754467168 [label="result1
 (0)" fillcolor=orange]
	3127802203728 -> 3127754467088 [dir=none]
	3127754467088 [label="result2
 (0)" fillcolor=orange]
	3127802203728 -> 3127667795328 [dir=none]
	3127667795328 [label="running_mean
 (256)" fillcolor=orange]
	3127802203728 -> 3127667795728 [dir=none]
	3127667795728 [label="running_var
 (256)" fillcolor=orange]
	3127802203728 -> 3127667795488 [dir=none]
	3127667795488 [label="weight
 (256)" fillcolor=orange]
	3127802203728 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802203536 -> 3127802203728
	3127802203536 -> 3127754460288 [dir=none]
	3127754460288 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802203536 -> 3127667795568 [dir=none]
	3127667795568 [label="weight
 (256, 128, 3, 3)" fillcolor=orange]
	3127802203536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3127802200944 -> 3127802203536
	3127802200944 -> 3127754467248 [dir=none]
	3127754467248 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	3127802200944 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802204160 -> 3127802200944
	3127802204160 [label="AddBackward0
------------
alpha: 1"]
	3127802203968 -> 3127802204160
	3127802203968 -> 3127754460208 [dir=none]
	3127754460208 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802203968 -> 3127754467728 [dir=none]
	3127754467728 [label="result1
 (0)" fillcolor=orange]
	3127802203968 -> 3127754467648 [dir=none]
	3127754467648 [label="result2
 (0)" fillcolor=orange]
	3127802203968 -> 3127667794048 [dir=none]
	3127667794048 [label="running_mean
 (128)" fillcolor=orange]
	3127802203968 -> 3127667794448 [dir=none]
	3127667794448 [label="running_var
 (128)" fillcolor=orange]
	3127802203968 -> 3127667794208 [dir=none]
	3127667794208 [label="weight
 (128)" fillcolor=orange]
	3127802203968 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802203920 -> 3127802203968
	3127802203920 -> 3127754459968 [dir=none]
	3127754459968 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802203920 -> 3127667794288 [dir=none]
	3127667794288 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3127802203920 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127802203680 -> 3127802203920
	3127802203680 -> 3127754467808 [dir=none]
	3127754467808 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	3127802203680 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802204736 -> 3127802203680
	3127802204736 -> 3127754460128 [dir=none]
	3127754460128 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802204736 -> 3127754468208 [dir=none]
	3127754468208 [label="result1
 (0)" fillcolor=orange]
	3127802204736 -> 3127754468128 [dir=none]
	3127754468128 [label="result2
 (0)" fillcolor=orange]
	3127802204736 -> 3127667793408 [dir=none]
	3127667793408 [label="running_mean
 (128)" fillcolor=orange]
	3127802204736 -> 3127667793808 [dir=none]
	3127667793808 [label="running_var
 (128)" fillcolor=orange]
	3127802204736 -> 3127667793568 [dir=none]
	3127667793568 [label="weight
 (128)" fillcolor=orange]
	3127802204736 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802204544 -> 3127802204736
	3127802204544 -> 3127754459888 [dir=none]
	3127754459888 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802204544 -> 3127667793648 [dir=none]
	3127667793648 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3127802204544 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127802204112 -> 3127802204544
	3127802204112 -> 3127754468288 [dir=none]
	3127754468288 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	3127802204112 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802205216 -> 3127802204112
	3127802205216 [label="AddBackward0
------------
alpha: 1"]
	3127802205024 -> 3127802205216
	3127802205024 -> 3127754459808 [dir=none]
	3127754459808 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802205024 -> 3127754468768 [dir=none]
	3127754468768 [label="result1
 (0)" fillcolor=orange]
	3127802205024 -> 3127754468688 [dir=none]
	3127754468688 [label="result2
 (0)" fillcolor=orange]
	3127802205024 -> 3127667792768 [dir=none]
	3127667792768 [label="running_mean
 (128)" fillcolor=orange]
	3127802205024 -> 3127667793168 [dir=none]
	3127667793168 [label="running_var
 (128)" fillcolor=orange]
	3127802205024 -> 3127667792928 [dir=none]
	3127667792928 [label="weight
 (128)" fillcolor=orange]
	3127802205024 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802204976 -> 3127802205024
	3127802204976 -> 3127754459728 [dir=none]
	3127754459728 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802204976 -> 3127667793008 [dir=none]
	3127667793008 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	3127802204976 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127802205264 -> 3127802204976
	3127802205264 -> 3127754468848 [dir=none]
	3127754468848 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	3127802205264 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802205696 -> 3127802205264
	3127802205696 -> 3127754459648 [dir=none]
	3127754459648 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802205696 -> 3127754469248 [dir=none]
	3127754469248 [label="result1
 (0)" fillcolor=orange]
	3127802205696 -> 3127754469168 [dir=none]
	3127754469168 [label="result2
 (0)" fillcolor=orange]
	3127802205696 -> 3127667792128 [dir=none]
	3127667792128 [label="running_mean
 (128)" fillcolor=orange]
	3127802205696 -> 3127667792528 [dir=none]
	3127667792528 [label="running_var
 (128)" fillcolor=orange]
	3127802205696 -> 3127667792288 [dir=none]
	3127667792288 [label="weight
 (128)" fillcolor=orange]
	3127802205696 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802205504 -> 3127802205696
	3127802205504 -> 3127754459568 [dir=none]
	3127754459568 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802205504 -> 3127667792368 [dir=none]
	3127667792368 [label="weight
 (128, 64, 3, 3)" fillcolor=orange]
	3127802205504 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3127802204448 -> 3127802205504
	3127802204448 -> 3127754469568 [dir=none]
	3127754469568 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	3127802204448 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802206128 -> 3127802204448
	3127802206128 [label="AddBackward0
------------
alpha: 1"]
	3127802205936 -> 3127802206128
	3127802205936 -> 3127754459488 [dir=none]
	3127754459488 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802205936 -> 3127754469808 [dir=none]
	3127754469808 [label="result1
 (0)" fillcolor=orange]
	3127802205936 -> 3127754468528 [dir=none]
	3127754468528 [label="result2
 (0)" fillcolor=orange]
	3127802205936 -> 3127667790928 [dir=none]
	3127667790928 [label="running_mean
 (64)" fillcolor=orange]
	3127802205936 -> 3127667791328 [dir=none]
	3127667791328 [label="running_var
 (64)" fillcolor=orange]
	3127802205936 -> 3127667791088 [dir=none]
	3127667791088 [label="weight
 (64)" fillcolor=orange]
	3127802205936 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802205888 -> 3127802205936
	3127802205888 -> 3127754459408 [dir=none]
	3127754459408 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802205888 -> 3127667791168 [dir=none]
	3127667791168 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3127802205888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127802205648 -> 3127802205888
	3127802205648 -> 3127754468448 [dir=none]
	3127754468448 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	3127802205648 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802206704 -> 3127802205648
	3127802206704 -> 3127754459168 [dir=none]
	3127754459168 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802206704 -> 3127754470128 [dir=none]
	3127754470128 [label="result1
 (0)" fillcolor=orange]
	3127802206704 -> 3127754470288 [dir=none]
	3127754470288 [label="result2
 (0)" fillcolor=orange]
	3127802206704 -> 3127667789008 [dir=none]
	3127667789008 [label="running_mean
 (64)" fillcolor=orange]
	3127802206704 -> 3127667790688 [dir=none]
	3127667790688 [label="running_var
 (64)" fillcolor=orange]
	3127802206704 -> 3127667790448 [dir=none]
	3127667790448 [label="weight
 (64)" fillcolor=orange]
	3127802206704 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802206512 -> 3127802206704
	3127802206512 -> 3127754458688 [dir=none]
	3127754458688 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802206512 -> 3127667790528 [dir=none]
	3127667790528 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3127802206512 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127802206080 -> 3127802206512
	3127802206080 -> 3127754470608 [dir=none]
	3127754470608 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	3127802206080 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802207184 -> 3127802206080
	3127802207184 [label="AddBackward0
------------
alpha: 1"]
	3127802206992 -> 3127802207184
	3127802206992 -> 3127754459328 [dir=none]
	3127754459328 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802206992 -> 3127754470848 [dir=none]
	3127754470848 [label="result1
 (0)" fillcolor=orange]
	3127802206992 -> 3127754470048 [dir=none]
	3127754470048 [label="result2
 (0)" fillcolor=orange]
	3127802206992 -> 3127667789728 [dir=none]
	3127667789728 [label="running_mean
 (64)" fillcolor=orange]
	3127802206992 -> 3127667790128 [dir=none]
	3127667790128 [label="running_var
 (64)" fillcolor=orange]
	3127802206992 -> 3127667789888 [dir=none]
	3127667789888 [label="weight
 (64)" fillcolor=orange]
	3127802206992 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802206944 -> 3127802206992
	3127802206944 -> 3127754458608 [dir=none]
	3127754458608 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802206944 -> 3127667789968 [dir=none]
	3127667789968 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3127802206944 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127802207232 -> 3127802206944
	3127802207232 -> 3127754469488 [dir=none]
	3127754469488 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	3127802207232 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802207664 -> 3127802207232
	3127802207664 -> 3127754459248 [dir=none]
	3127754459248 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802207664 -> 3127754471168 [dir=none]
	3127754471168 [label="result1
 (0)" fillcolor=orange]
	3127802207664 -> 3127754471328 [dir=none]
	3127754471328 [label="result2
 (0)" fillcolor=orange]
	3127802207664 -> 3127667789088 [dir=none]
	3127667789088 [label="running_mean
 (64)" fillcolor=orange]
	3127802207664 -> 3127667789488 [dir=none]
	3127667789488 [label="running_var
 (64)" fillcolor=orange]
	3127802207664 -> 3127667789248 [dir=none]
	3127667789248 [label="weight
 (64)" fillcolor=orange]
	3127802207664 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802207472 -> 3127802207664
	3127802207472 -> 3127754458928 [dir=none]
	3127754458928 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802207472 -> 3127667789328 [dir=none]
	3127667789328 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	3127802207472 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	3127802207136 -> 3127802207472
	3127802207136 -> 3127754471648 [dir=none]
	3127754471648 [label="result1
 (1, 64, 56, 56)" fillcolor=orange]
	3127802207136 -> 3127668442288 [dir=none]
	3127668442288 [label="self
 (1, 64, 112, 112)" fillcolor=orange]
	3127802207136 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (3, 3)
padding    :         (1, 1)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	3127667693296 -> 3127802207136
	3127667693296 -> 3127754471808 [dir=none]
	3127754471808 [label="result
 (1, 64, 112, 112)" fillcolor=orange]
	3127667693296 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	3127802207088 -> 3127667693296
	3127802207088 -> 3127668450928 [dir=none]
	3127668450928 [label="input
 (1, 64, 112, 112)" fillcolor=orange]
	3127802207088 -> 3127754471968 [dir=none]
	3127754471968 [label="result1
 (0)" fillcolor=orange]
	3127802207088 -> 3127754471568 [dir=none]
	3127754471568 [label="result2
 (0)" fillcolor=orange]
	3127802207088 -> 3127168793440 [dir=none]
	3127168793440 [label="running_mean
 (64)" fillcolor=orange]
	3127802207088 -> 3127667788768 [dir=none]
	3127667788768 [label="running_var
 (64)" fillcolor=orange]
	3127802207088 -> 3127667788688 [dir=none]
	3127667788688 [label="weight
 (64)" fillcolor=orange]
	3127802207088 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802207904 -> 3127802207088
	3127802207904 -> 3127668410080 [dir=none]
	3127668410080 [label="input
 (1, 3, 224, 224)" fillcolor=orange]
	3127802207904 -> 3127667788608 [dir=none]
	3127667788608 [label="weight
 (64, 3, 7, 7)" fillcolor=orange]
	3127802207904 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (3, 3)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3127802207376 -> 3127802207904
	3127667788608 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	3127667788608 -> 3127802207376
	3127802207376 [label=AccumulateGrad]
	3127802207952 -> 3127802207088
	3127667788688 [label="bn1.weight
 (64)" fillcolor=lightblue]
	3127667788688 -> 3127802207952
	3127802207952 [label=AccumulateGrad]
	3127802206032 -> 3127802207088
	3127169906112 [label="bn1.bias
 (64)" fillcolor=lightblue]
	3127169906112 -> 3127802206032
	3127802206032 [label=AccumulateGrad]
	3127802206416 -> 3127802207472
	3127667789328 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3127667789328 -> 3127802206416
	3127802206416 [label=AccumulateGrad]
	3127802207424 -> 3127802207664
	3127667789248 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	3127667789248 -> 3127802207424
	3127802207424 [label=AccumulateGrad]
	3127802207712 -> 3127802207664
	3127667789408 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	3127667789408 -> 3127802207712
	3127802207712 [label=AccumulateGrad]
	3127802207328 -> 3127802206944
	3127667789968 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3127667789968 -> 3127802207328
	3127802207328 [label=AccumulateGrad]
	3127802206608 -> 3127802206992
	3127667789888 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	3127667789888 -> 3127802206608
	3127802206608 [label=AccumulateGrad]
	3127802206896 -> 3127802206992
	3127667790048 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	3127667790048 -> 3127802206896
	3127802206896 [label=AccumulateGrad]
	3127802207136 -> 3127802207184
	3127802206224 -> 3127802206512
	3127667790528 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3127667790528 -> 3127802206224
	3127802206224 [label=AccumulateGrad]
	3127802206464 -> 3127802206704
	3127667790448 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	3127667790448 -> 3127802206464
	3127802206464 [label=AccumulateGrad]
	3127802206752 -> 3127802206704
	3127667790608 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	3127667790608 -> 3127802206752
	3127802206752 [label=AccumulateGrad]
	3127802206368 -> 3127802205888
	3127667791168 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3127667791168 -> 3127802206368
	3127802206368 [label=AccumulateGrad]
	3127802205120 -> 3127802205936
	3127667791088 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	3127667791088 -> 3127802205120
	3127802205120 [label=AccumulateGrad]
	3127802205840 -> 3127802205936
	3127667791248 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	3127667791248 -> 3127802205840
	3127802205840 [label=AccumulateGrad]
	3127802206080 -> 3127802206128
	3127802204880 -> 3127802205504
	3127667792368 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	3127667792368 -> 3127802204880
	3127802204880 [label=AccumulateGrad]
	3127802205456 -> 3127802205696
	3127667792288 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	3127667792288 -> 3127802205456
	3127802205456 [label=AccumulateGrad]
	3127802205744 -> 3127802205696
	3127667792448 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	3127667792448 -> 3127802205744
	3127802205744 [label=AccumulateGrad]
	3127802205360 -> 3127802204976
	3127667793008 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3127667793008 -> 3127802205360
	3127802205360 [label=AccumulateGrad]
	3127802204640 -> 3127802205024
	3127667792928 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	3127667792928 -> 3127802204640
	3127802204640 [label=AccumulateGrad]
	3127802204928 -> 3127802205024
	3127667793088 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	3127667793088 -> 3127802204928
	3127802204928 [label=AccumulateGrad]
	3127802205168 -> 3127802205216
	3127802205168 -> 3127754460048 [dir=none]
	3127754460048 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802205168 -> 3127802269520 [dir=none]
	3127802269520 [label="result1
 (0)" fillcolor=orange]
	3127802205168 -> 3127802269440 [dir=none]
	3127802269440 [label="result2
 (0)" fillcolor=orange]
	3127802205168 -> 3127667791568 [dir=none]
	3127667791568 [label="running_mean
 (128)" fillcolor=orange]
	3127802205168 -> 3127667791888 [dir=none]
	3127667791888 [label="running_var
 (128)" fillcolor=orange]
	3127802205168 -> 3127667791728 [dir=none]
	3127667791728 [label="weight
 (128)" fillcolor=orange]
	3127802205168 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802205552 -> 3127802205168
	3127802205552 -> 3127754459568 [dir=none]
	3127754459568 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	3127802205552 -> 3127667791648 [dir=none]
	3127667791648 [label="weight
 (128, 64, 1, 1)" fillcolor=orange]
	3127802205552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3127802204448 -> 3127802205552
	3127802206320 -> 3127802205552
	3127667791648 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	3127667791648 -> 3127802206320
	3127802206320 [label=AccumulateGrad]
	3127802205984 -> 3127802205168
	3127667791728 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	3127667791728 -> 3127802205984
	3127802205984 [label=AccumulateGrad]
	3127802205312 -> 3127802205168
	3127667791808 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	3127667791808 -> 3127802205312
	3127802205312 [label=AccumulateGrad]
	3127802204256 -> 3127802204544
	3127667793648 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3127667793648 -> 3127802204256
	3127802204256 [label=AccumulateGrad]
	3127802204496 -> 3127802204736
	3127667793568 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	3127667793568 -> 3127802204496
	3127802204496 [label=AccumulateGrad]
	3127802204784 -> 3127802204736
	3127667793728 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	3127667793728 -> 3127802204784
	3127802204784 [label=AccumulateGrad]
	3127802204400 -> 3127802203920
	3127667794288 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3127667794288 -> 3127802204400
	3127802204400 [label=AccumulateGrad]
	3127802203152 -> 3127802203968
	3127667794208 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	3127667794208 -> 3127802203152
	3127802203152 [label=AccumulateGrad]
	3127802203872 -> 3127802203968
	3127667794368 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	3127667794368 -> 3127802203872
	3127802203872 [label=AccumulateGrad]
	3127802204112 -> 3127802204160
	3127802202864 -> 3127802203536
	3127667795568 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	3127667795568 -> 3127802202864
	3127802202864 [label=AccumulateGrad]
	3127802203488 -> 3127802203728
	3127667795488 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	3127667795488 -> 3127802203488
	3127802203488 [label=AccumulateGrad]
	3127802203776 -> 3127802203728
	3127667795648 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	3127667795648 -> 3127802203776
	3127802203776 [label=AccumulateGrad]
	3127802203392 -> 3127802203008
	3127667796208 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3127667796208 -> 3127802203392
	3127802203392 [label=AccumulateGrad]
	3127802202528 -> 3127802203056
	3127667796128 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	3127667796128 -> 3127802202528
	3127802202528 [label=AccumulateGrad]
	3127802202960 -> 3127802203056
	3127667796288 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	3127667796288 -> 3127802202960
	3127802202960 [label=AccumulateGrad]
	3127802203200 -> 3127802203248
	3127802203200 -> 3127754460768 [dir=none]
	3127754460768 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127802203200 -> 3127802273600 [dir=none]
	3127802273600 [label="result1
 (0)" fillcolor=orange]
	3127802203200 -> 3127802273520 [dir=none]
	3127802273520 [label="result2
 (0)" fillcolor=orange]
	3127802203200 -> 3127667794768 [dir=none]
	3127667794768 [label="running_mean
 (256)" fillcolor=orange]
	3127802203200 -> 3127667795088 [dir=none]
	3127667795088 [label="running_var
 (256)" fillcolor=orange]
	3127802203200 -> 3127667794928 [dir=none]
	3127667794928 [label="weight
 (256)" fillcolor=orange]
	3127802203200 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127802203584 -> 3127802203200
	3127802203584 -> 3127754460288 [dir=none]
	3127754460288 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	3127802203584 -> 3127667794848 [dir=none]
	3127667794848 [label="weight
 (256, 128, 1, 1)" fillcolor=orange]
	3127802203584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3127802200944 -> 3127802203584
	3127802204352 -> 3127802203584
	3127667794848 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	3127667794848 -> 3127802204352
	3127802204352 [label=AccumulateGrad]
	3127802204016 -> 3127802203200
	3127667794928 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	3127667794928 -> 3127802204016
	3127802204016 [label=AccumulateGrad]
	3127802203344 -> 3127802203200
	3127667795008 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	3127667795008 -> 3127802203344
	3127802203344 [label=AccumulateGrad]
	3127802200176 -> 3127802201520
	3127667796848 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3127667796848 -> 3127802200176
	3127802200176 [label=AccumulateGrad]
	3127802201424 -> 3127802202912
	3127667796768 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	3127667796768 -> 3127802201424
	3127802201424 [label=AccumulateGrad]
	3127802200992 -> 3127802202912
	3127667796928 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	3127667796928 -> 3127802200992
	3127802200992 [label=AccumulateGrad]
	3127802202336 -> 3127667692432
	3127667797488 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3127667797488 -> 3127802202336
	3127802202336 [label=AccumulateGrad]
	3127667690512 -> 3127667697328
	3127667797408 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	3127667797408 -> 3127667690512
	3127667690512 [label=AccumulateGrad]
	3127667700976 -> 3127667697328
	3127667797568 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	3127667797568 -> 3127667700976
	3127667700976 [label=AccumulateGrad]
	3127667690272 -> 3127667694016
	3127667690368 -> 3127719324032
	3127667798768 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	3127667798768 -> 3127667690368
	3127667690368 [label=AccumulateGrad]
	3127719325904 -> 3127719322976
	3127667798688 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	3127667798688 -> 3127719325904
	3127719325904 [label=AccumulateGrad]
	3127719327968 -> 3127719322976
	3127667798848 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	3127667798848 -> 3127719327968
	3127719327968 [label=AccumulateGrad]
	3127719328448 -> 3127719329024
	3127667799408 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3127667799408 -> 3127719328448
	3127719328448 [label=AccumulateGrad]
	3127719322496 -> 3127719329168
	3127667799328 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	3127667799328 -> 3127719322496
	3127719322496 [label=AccumulateGrad]
	3127719323600 -> 3127719329168
	3127667799488 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	3127667799488 -> 3127719323600
	3127719323600 [label=AccumulateGrad]
	3127719329216 -> 3127719322448
	3127719329216 -> 3127754461488 [dir=none]
	3127754461488 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	3127719329216 -> 3127802277600 [dir=none]
	3127802277600 [label="result1
 (0)" fillcolor=orange]
	3127719329216 -> 3127802277680 [dir=none]
	3127802277680 [label="result2
 (0)" fillcolor=orange]
	3127719329216 -> 3127667797968 [dir=none]
	3127667797968 [label="running_mean
 (512)" fillcolor=orange]
	3127719329216 -> 3127667798288 [dir=none]
	3127667798288 [label="running_var
 (512)" fillcolor=orange]
	3127719329216 -> 3127667798128 [dir=none]
	3127667798128 [label="weight
 (512)" fillcolor=orange]
	3127719329216 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	3127719323984 -> 3127719329216
	3127719323984 -> 3127754461008 [dir=none]
	3127754461008 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	3127719323984 -> 3127667798048 [dir=none]
	3127667798048 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	3127719323984 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	3127667691568 -> 3127719323984
	3127667698912 -> 3127719323984
	3127667798048 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	3127667798048 -> 3127667698912
	3127667698912 [label=AccumulateGrad]
	3127719329408 -> 3127719329216
	3127667798128 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	3127667798128 -> 3127719329408
	3127719329408 [label=AccumulateGrad]
	3127719329072 -> 3127719329216
	3127667798208 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	3127667798208 -> 3127719329072
	3127719329072 [label=AccumulateGrad]
	3127719327248 -> 3127718476432
	3127667800048 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3127667800048 -> 3127719327248
	3127719327248 [label=AccumulateGrad]
	3127718473456 -> 3127718471536
	3127667799968 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	3127667799968 -> 3127718473456
	3127718473456 [label=AccumulateGrad]
	3127718473072 -> 3127718471536
	3127667800128 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	3127667800128 -> 3127718473072
	3127718473072 [label=AccumulateGrad]
	3127718477440 -> 3127718533232
	3127667800688 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3127667800688 -> 3127718477440
	3127718477440 [label=AccumulateGrad]
	3127718468704 -> 3127718532608
	3127667800608 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	3127667800608 -> 3127718468704
	3127718468704 [label=AccumulateGrad]
	3127718476000 -> 3127718532608
	3127667800768 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	3127667800768 -> 3127718476000
	3127718476000 [label=AccumulateGrad]
	3127718539568 -> 3127718531936
	3127170086800 -> 3127656284112
	3127170086800 [label=TBackward0]
	3127718534096 -> 3127170086800
	3127668064112 [label="fc.weight
 (2, 512)" fillcolor=lightblue]
	3127668064112 -> 3127718534096
	3127718534096 [label=AccumulateGrad]
	3127656284112 -> 3127754461808
}
