digraph {
	graph [size="113.85,113.85"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2976300570512 [label="
 (1, 5)" fillcolor=darkolivegreen1]
	2976293696464 -> 2976300570608 [dir=none]
	2976300570608 [label="mat1
 (1, 512)" fillcolor=orange]
	2976293696464 -> 2976300570704 [dir=none]
	2976300570704 [label="mat2
 (512, 5)" fillcolor=orange]
	2976293696464 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 512)
mat1_sym_strides:       (512, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (512, 5)
mat2_sym_strides:       (1, 512)"]
	2976293696512 -> 2976293696464
	2976276381136 [label="fc.bias
 (5)" fillcolor=lightblue]
	2976276381136 -> 2976293696512
	2976293696512 [label=AccumulateGrad]
	2976293696368 -> 2976293696464
	2976293696368 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 512, 1, 1)"]
	2976293696560 -> 2976293696368
	2976293696560 [label="MeanBackward1
----------------------------------------
dim           : (4294967295, 4294967294)
keepdim       :                     True
self_sym_numel:                    86528
self_sym_sizes:         (1, 512, 13, 13)"]
	2976293697232 -> 2976293696560
	2976293697232 -> 2976300568688 [dir=none]
	2976300568688 [label="result
 (1, 512, 13, 13)" fillcolor=orange]
	2976293697232 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976293697088 -> 2976293697232
	2976293697088 [label="AddBackward0
------------
alpha: 1"]
	2976293697136 -> 2976293697088
	2976293697136 -> 2976300569552 [dir=none]
	2976300569552 [label="input
 (1, 512, 13, 13)" fillcolor=orange]
	2976293697136 -> 2976300571856 [dir=none]
	2976300571856 [label="result1
 (0)" fillcolor=orange]
	2976293697136 -> 2976300571760 [dir=none]
	2976300571760 [label="result2
 (0)" fillcolor=orange]
	2976293697136 -> 2976276368176 [dir=none]
	2976276368176 [label="running_mean
 (512)" fillcolor=orange]
	2976293697136 -> 2976276368560 [dir=none]
	2976276368560 [label="running_var
 (512)" fillcolor=orange]
	2976293697136 -> 2976276368368 [dir=none]
	2976276368368 [label="weight
 (512)" fillcolor=orange]
	2976293697136 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976293697424 -> 2976293697136
	2976293697424 -> 2976300568208 [dir=none]
	2976300568208 [label="input
 (1, 512, 13, 13)" fillcolor=orange]
	2976293697424 -> 2976276368272 [dir=none]
	2976276368272 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	2976293697424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976293697616 -> 2976293697424
	2976293697616 -> 2976300573488 [dir=none]
	2976300573488 [label="result
 (1, 512, 13, 13)" fillcolor=orange]
	2976293697616 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976293697760 -> 2976293697616
	2976293697760 -> 2976300568880 [dir=none]
	2976300568880 [label="input
 (1, 512, 13, 13)" fillcolor=orange]
	2976293697760 -> 2976300573008 [dir=none]
	2976300573008 [label="result1
 (0)" fillcolor=orange]
	2976293697760 -> 2976300573296 [dir=none]
	2976300573296 [label="result2
 (0)" fillcolor=orange]
	2976293697760 -> 2976276367600 [dir=none]
	2976276367600 [label="running_mean
 (512)" fillcolor=orange]
	2976293697760 -> 2976276367984 [dir=none]
	2976276367984 [label="running_var
 (512)" fillcolor=orange]
	2976293697760 -> 2976276367792 [dir=none]
	2976276367792 [label="weight
 (512)" fillcolor=orange]
	2976293697760 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976293697856 -> 2976293697760
	2976293697856 -> 2976300577136 [dir=none]
	2976300577136 [label="input
 (1, 512, 13, 13)" fillcolor=orange]
	2976293697856 -> 2976276367696 [dir=none]
	2976276367696 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	2976293697856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976293697040 -> 2976293697856
	2976293697040 -> 2976300574832 [dir=none]
	2976300574832 [label="result
 (1, 512, 13, 13)" fillcolor=orange]
	2976293697040 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976293698144 -> 2976293697040
	2976293698144 [label="AddBackward0
------------
alpha: 1"]
	2976293698240 -> 2976293698144
	2976293698240 -> 2976300565520 [dir=none]
	2976300565520 [label="input
 (1, 512, 13, 13)" fillcolor=orange]
	2976293698240 -> 2976300574640 [dir=none]
	2976300574640 [label="result1
 (0)" fillcolor=orange]
	2976293698240 -> 2976300574928 [dir=none]
	2976300574928 [label="result2
 (0)" fillcolor=orange]
	2976293698240 -> 2976276367024 [dir=none]
	2976276367024 [label="running_mean
 (512)" fillcolor=orange]
	2976293698240 -> 2976276367408 [dir=none]
	2976276367408 [label="running_var
 (512)" fillcolor=orange]
	2976293698240 -> 2976276367216 [dir=none]
	2976276367216 [label="weight
 (512)" fillcolor=orange]
	2976293698240 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976293698384 -> 2976293698240
	2976293698384 -> 2976300571280 [dir=none]
	2976300571280 [label="input
 (1, 512, 13, 13)" fillcolor=orange]
	2976293698384 -> 2976276367120 [dir=none]
	2976276367120 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	2976293698384 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976293698576 -> 2976293698384
	2976293698576 -> 2976300576176 [dir=none]
	2976300576176 [label="result
 (1, 512, 13, 13)" fillcolor=orange]
	2976293698576 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976293698720 -> 2976293698576
	2976293698720 -> 2976300568304 [dir=none]
	2976300568304 [label="input
 (1, 512, 13, 13)" fillcolor=orange]
	2976293698720 -> 2976300576080 [dir=none]
	2976300576080 [label="result1
 (0)" fillcolor=orange]
	2976293698720 -> 2976300577232 [dir=none]
	2976300577232 [label="result2
 (0)" fillcolor=orange]
	2976293698720 -> 2976276366448 [dir=none]
	2976276366448 [label="running_mean
 (512)" fillcolor=orange]
	2976293698720 -> 2976276366832 [dir=none]
	2976276366832 [label="running_var
 (512)" fillcolor=orange]
	2976293698720 -> 2976276366640 [dir=none]
	2976276366640 [label="weight
 (512)" fillcolor=orange]
	2976293698720 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976293698816 -> 2976293698720
	2976293698816 -> 2976300567728 [dir=none]
	2976300567728 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976293698816 -> 2976276366544 [dir=none]
	2976276366544 [label="weight
 (512, 256, 3, 3)" fillcolor=orange]
	2976293698816 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	2976293699008 -> 2976293698816
	2976293699008 -> 2976300578000 [dir=none]
	2976300578000 [label="result
 (1, 256, 25, 25)" fillcolor=orange]
	2976293699008 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976293699152 -> 2976293699008
	2976293699152 [label="AddBackward0
------------
alpha: 1"]
	2976293699248 -> 2976293699152
	2976293699248 -> 2976300570992 [dir=none]
	2976300570992 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976293699248 -> 2976300578480 [dir=none]
	2976300578480 [label="result1
 (0)" fillcolor=orange]
	2976293699248 -> 2976300578768 [dir=none]
	2976300578768 [label="result2
 (0)" fillcolor=orange]
	2976293699248 -> 2976276217776 [dir=none]
	2976276217776 [label="running_mean
 (256)" fillcolor=orange]
	2976293699248 -> 2976276365680 [dir=none]
	2976276365680 [label="running_var
 (256)" fillcolor=orange]
	2976293699248 -> 2976276365488 [dir=none]
	2976276365488 [label="weight
 (256)" fillcolor=orange]
	2976293699248 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976293699392 -> 2976293699248
	2976293699392 -> 2976300313936 [dir=none]
	2976300313936 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976293699392 -> 2976276365392 [dir=none]
	2976276365392 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	2976293699392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976293699536 -> 2976293699392
	2976293699536 -> 2976300579536 [dir=none]
	2976300579536 [label="result
 (1, 256, 25, 25)" fillcolor=orange]
	2976293699536 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300646608 -> 2976293699536
	2976300646608 -> 2976300314320 [dir=none]
	2976300314320 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976300646608 -> 2976300579824 [dir=none]
	2976300579824 [label="result1
 (0)" fillcolor=orange]
	2976300646608 -> 2976300580208 [dir=none]
	2976300580208 [label="result2
 (0)" fillcolor=orange]
	2976300646608 -> 2976276217200 [dir=none]
	2976276217200 [label="running_mean
 (256)" fillcolor=orange]
	2976300646608 -> 2976276217584 [dir=none]
	2976276217584 [label="running_var
 (256)" fillcolor=orange]
	2976300646608 -> 2976276217392 [dir=none]
	2976276217392 [label="weight
 (256)" fillcolor=orange]
	2976300646608 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300646704 -> 2976300646608
	2976300646704 -> 2976300314128 [dir=none]
	2976300314128 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976300646704 -> 2976276217296 [dir=none]
	2976276217296 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	2976300646704 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976293699200 -> 2976300646704
	2976293699200 -> 2976300662960 [dir=none]
	2976300662960 [label="result
 (1, 256, 25, 25)" fillcolor=orange]
	2976293699200 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300646992 -> 2976293699200
	2976300646992 [label="AddBackward0
------------
alpha: 1"]
	2976300647088 -> 2976300646992
	2976300647088 -> 2976300317104 [dir=none]
	2976300317104 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976300647088 -> 2976300663440 [dir=none]
	2976300663440 [label="result1
 (0)" fillcolor=orange]
	2976300647088 -> 2976300663728 [dir=none]
	2976300663728 [label="result2
 (0)" fillcolor=orange]
	2976300647088 -> 2976276216624 [dir=none]
	2976276216624 [label="running_mean
 (256)" fillcolor=orange]
	2976300647088 -> 2976276217008 [dir=none]
	2976276217008 [label="running_var
 (256)" fillcolor=orange]
	2976300647088 -> 2976276216816 [dir=none]
	2976276216816 [label="weight
 (256)" fillcolor=orange]
	2976300647088 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300647232 -> 2976300647088
	2976300647232 -> 2976300315568 [dir=none]
	2976300315568 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976300647232 -> 2976276216720 [dir=none]
	2976276216720 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	2976300647232 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976300647424 -> 2976300647232
	2976300647424 -> 2976300664496 [dir=none]
	2976300664496 [label="result
 (1, 256, 25, 25)" fillcolor=orange]
	2976300647424 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300647568 -> 2976300647424
	2976300647568 -> 2976300314800 [dir=none]
	2976300314800 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976300647568 -> 2976300664784 [dir=none]
	2976300664784 [label="result1
 (0)" fillcolor=orange]
	2976300647568 -> 2976300665168 [dir=none]
	2976300665168 [label="result2
 (0)" fillcolor=orange]
	2976300647568 -> 2976276216048 [dir=none]
	2976276216048 [label="running_mean
 (256)" fillcolor=orange]
	2976300647568 -> 2976276216432 [dir=none]
	2976276216432 [label="running_var
 (256)" fillcolor=orange]
	2976300647568 -> 2976276216240 [dir=none]
	2976276216240 [label="weight
 (256)" fillcolor=orange]
	2976300647568 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300647664 -> 2976300647568
	2976300647664 -> 2976300316624 [dir=none]
	2976300316624 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300647664 -> 2976276216144 [dir=none]
	2976276216144 [label="weight
 (256, 128, 3, 3)" fillcolor=orange]
	2976300647664 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	2976300647856 -> 2976300647664
	2976300647856 -> 2976300665936 [dir=none]
	2976300665936 [label="result
 (1, 128, 50, 50)" fillcolor=orange]
	2976300647856 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300648000 -> 2976300647856
	2976300648000 [label="AddBackward0
------------
alpha: 1"]
	2976300648096 -> 2976300648000
	2976300648096 -> 2976300305584 [dir=none]
	2976300305584 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300648096 -> 2976300666416 [dir=none]
	2976300666416 [label="result1
 (0)" fillcolor=orange]
	2976300648096 -> 2976300666704 [dir=none]
	2976300666704 [label="result2
 (0)" fillcolor=orange]
	2976300648096 -> 2976276214896 [dir=none]
	2976276214896 [label="running_mean
 (128)" fillcolor=orange]
	2976300648096 -> 2976276215280 [dir=none]
	2976276215280 [label="running_var
 (128)" fillcolor=orange]
	2976300648096 -> 2976276215088 [dir=none]
	2976276215088 [label="weight
 (128)" fillcolor=orange]
	2976300648096 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300648240 -> 2976300648096
	2976300648240 -> 2976300306064 [dir=none]
	2976300306064 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300648240 -> 2976276214992 [dir=none]
	2976276214992 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	2976300648240 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976300648432 -> 2976300648240
	2976300648432 -> 2976300667472 [dir=none]
	2976300667472 [label="result
 (1, 128, 50, 50)" fillcolor=orange]
	2976300648432 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300648576 -> 2976300648432
	2976300648576 -> 2976300315472 [dir=none]
	2976300315472 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300648576 -> 2976300667760 [dir=none]
	2976300667760 [label="result1
 (0)" fillcolor=orange]
	2976300648576 -> 2976300668144 [dir=none]
	2976300668144 [label="result2
 (0)" fillcolor=orange]
	2976300648576 -> 2976276214320 [dir=none]
	2976276214320 [label="running_mean
 (128)" fillcolor=orange]
	2976300648576 -> 2976276214704 [dir=none]
	2976276214704 [label="running_var
 (128)" fillcolor=orange]
	2976300648576 -> 2976276214512 [dir=none]
	2976276214512 [label="weight
 (128)" fillcolor=orange]
	2976300648576 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300648672 -> 2976300648576
	2976300648672 -> 2976300303664 [dir=none]
	2976300303664 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300648672 -> 2976276214416 [dir=none]
	2976276214416 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	2976300648672 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976300648048 -> 2976300648672
	2976300648048 -> 2976300668912 [dir=none]
	2976300668912 [label="result
 (1, 128, 50, 50)" fillcolor=orange]
	2976300648048 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300648960 -> 2976300648048
	2976300648960 [label="AddBackward0
------------
alpha: 1"]
	2976300649056 -> 2976300648960
	2976300649056 -> 2976300306160 [dir=none]
	2976300306160 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300649056 -> 2976300669392 [dir=none]
	2976300669392 [label="result1
 (0)" fillcolor=orange]
	2976300649056 -> 2976300669680 [dir=none]
	2976300669680 [label="result2
 (0)" fillcolor=orange]
	2976300649056 -> 2976276213744 [dir=none]
	2976276213744 [label="running_mean
 (128)" fillcolor=orange]
	2976300649056 -> 2976276214128 [dir=none]
	2976276214128 [label="running_var
 (128)" fillcolor=orange]
	2976300649056 -> 2976276213936 [dir=none]
	2976276213936 [label="weight
 (128)" fillcolor=orange]
	2976300649056 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300649200 -> 2976300649056
	2976300649200 -> 2976300314992 [dir=none]
	2976300314992 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300649200 -> 2976276213840 [dir=none]
	2976276213840 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	2976300649200 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976300649392 -> 2976300649200
	2976300649392 -> 2976300670448 [dir=none]
	2976300670448 [label="result
 (1, 128, 50, 50)" fillcolor=orange]
	2976300649392 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300649536 -> 2976300649392
	2976300649536 -> 2976300317200 [dir=none]
	2976300317200 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300649536 -> 2976300670736 [dir=none]
	2976300670736 [label="result1
 (0)" fillcolor=orange]
	2976300649536 -> 2976300671120 [dir=none]
	2976300671120 [label="result2
 (0)" fillcolor=orange]
	2976300649536 -> 2976276213168 [dir=none]
	2976276213168 [label="running_mean
 (128)" fillcolor=orange]
	2976300649536 -> 2976276213552 [dir=none]
	2976276213552 [label="running_var
 (128)" fillcolor=orange]
	2976300649536 -> 2976276213360 [dir=none]
	2976276213360 [label="weight
 (128)" fillcolor=orange]
	2976300649536 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300649632 -> 2976300649536
	2976300649632 -> 2976300302608 [dir=none]
	2976300302608 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300649632 -> 2976276213264 [dir=none]
	2976276213264 [label="weight
 (128, 64, 3, 3)" fillcolor=orange]
	2976300649632 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	2976300649824 -> 2976300649632
	2976300649824 -> 2976300671888 [dir=none]
	2976300671888 [label="result
 (1, 64, 100, 100)" fillcolor=orange]
	2976300649824 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300649968 -> 2976300649824
	2976300649968 [label="AddBackward0
------------
alpha: 1"]
	2976300650064 -> 2976300649968
	2976300650064 -> 2976300313648 [dir=none]
	2976300313648 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300650064 -> 2976300672368 [dir=none]
	2976300672368 [label="result1
 (0)" fillcolor=orange]
	2976300650064 -> 2976300672656 [dir=none]
	2976300672656 [label="result2
 (0)" fillcolor=orange]
	2976300650064 -> 2976276212016 [dir=none]
	2976276212016 [label="running_mean
 (64)" fillcolor=orange]
	2976300650064 -> 2976276212400 [dir=none]
	2976276212400 [label="running_var
 (64)" fillcolor=orange]
	2976300650064 -> 2976276212208 [dir=none]
	2976276212208 [label="weight
 (64)" fillcolor=orange]
	2976300650064 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300650208 -> 2976300650064
	2976300650208 -> 2976300316720 [dir=none]
	2976300316720 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300650208 -> 2976276212112 [dir=none]
	2976276212112 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	2976300650208 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976300650400 -> 2976300650208
	2976300650400 -> 2976300673424 [dir=none]
	2976300673424 [label="result
 (1, 64, 100, 100)" fillcolor=orange]
	2976300650400 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300650544 -> 2976300650400
	2976300650544 -> 2976300158704 [dir=none]
	2976300158704 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300650544 -> 2976300673712 [dir=none]
	2976300673712 [label="result1
 (0)" fillcolor=orange]
	2976300650544 -> 2976300674096 [dir=none]
	2976300674096 [label="result2
 (0)" fillcolor=orange]
	2976300650544 -> 2976276211440 [dir=none]
	2976276211440 [label="running_mean
 (64)" fillcolor=orange]
	2976300650544 -> 2976276211824 [dir=none]
	2976276211824 [label="running_var
 (64)" fillcolor=orange]
	2976300650544 -> 2976276211632 [dir=none]
	2976276211632 [label="weight
 (64)" fillcolor=orange]
	2976300650544 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300650640 -> 2976300650544
	2976300650640 -> 2976300166960 [dir=none]
	2976300166960 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300650640 -> 2976276211536 [dir=none]
	2976276211536 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	2976300650640 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976300650016 -> 2976300650640
	2976300650016 -> 2976300674864 [dir=none]
	2976300674864 [label="result
 (1, 64, 100, 100)" fillcolor=orange]
	2976300650016 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300650928 -> 2976300650016
	2976300650928 [label="AddBackward0
------------
alpha: 1"]
	2976300651024 -> 2976300650928
	2976300651024 -> 2976300168400 [dir=none]
	2976300168400 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300651024 -> 2976300675344 [dir=none]
	2976300675344 [label="result1
 (0)" fillcolor=orange]
	2976300651024 -> 2976300675632 [dir=none]
	2976300675632 [label="result2
 (0)" fillcolor=orange]
	2976300651024 -> 2976276210864 [dir=none]
	2976276210864 [label="running_mean
 (64)" fillcolor=orange]
	2976300651024 -> 2976276211248 [dir=none]
	2976276211248 [label="running_var
 (64)" fillcolor=orange]
	2976300651024 -> 2976276211056 [dir=none]
	2976276211056 [label="weight
 (64)" fillcolor=orange]
	2976300651024 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300651168 -> 2976300651024
	2976300651168 -> 2976300163792 [dir=none]
	2976300163792 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300651168 -> 2976276210960 [dir=none]
	2976276210960 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	2976300651168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976300651360 -> 2976300651168
	2976300651360 -> 2976300676400 [dir=none]
	2976300676400 [label="result
 (1, 64, 100, 100)" fillcolor=orange]
	2976300651360 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300651504 -> 2976300651360
	2976300651504 -> 2976300166864 [dir=none]
	2976300166864 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300651504 -> 2976300676688 [dir=none]
	2976300676688 [label="result1
 (0)" fillcolor=orange]
	2976300651504 -> 2976300677072 [dir=none]
	2976300677072 [label="result2
 (0)" fillcolor=orange]
	2976300651504 -> 2976276210288 [dir=none]
	2976276210288 [label="running_mean
 (64)" fillcolor=orange]
	2976300651504 -> 2976276210672 [dir=none]
	2976276210672 [label="running_var
 (64)" fillcolor=orange]
	2976300651504 -> 2976276210480 [dir=none]
	2976276210480 [label="weight
 (64)" fillcolor=orange]
	2976300651504 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300651600 -> 2976300651504
	2976300651600 -> 2976300163888 [dir=none]
	2976300163888 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300651600 -> 2976276210384 [dir=none]
	2976276210384 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	2976300651600 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2976300650976 -> 2976300651600
	2976300650976 -> 2976300677840 [dir=none]
	2976300677840 [label="result1
 (1, 64, 100, 100)" fillcolor=orange]
	2976300650976 -> 2976300170032 [dir=none]
	2976300170032 [label="self
 (1, 64, 200, 200)" fillcolor=orange]
	2976300650976 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (3, 3)
padding    :         (1, 1)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	2976300651888 -> 2976300650976
	2976300651888 -> 2976300678224 [dir=none]
	2976300678224 [label="result
 (1, 64, 200, 200)" fillcolor=orange]
	2976300651888 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2976300651984 -> 2976300651888
	2976300651984 -> 2976300161392 [dir=none]
	2976300161392 [label="input
 (1, 64, 200, 200)" fillcolor=orange]
	2976300651984 -> 2976300678512 [dir=none]
	2976300678512 [label="result1
 (0)" fillcolor=orange]
	2976300651984 -> 2976300678896 [dir=none]
	2976300678896 [label="result2
 (0)" fillcolor=orange]
	2976300651984 -> 2976276206832 [dir=none]
	2976276206832 [label="running_mean
 (64)" fillcolor=orange]
	2976300651984 -> 2976276210096 [dir=none]
	2976276210096 [label="running_var
 (64)" fillcolor=orange]
	2976300651984 -> 2976276209904 [dir=none]
	2976276209904 [label="weight
 (64)" fillcolor=orange]
	2976300651984 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300652080 -> 2976300651984
	2976300652080 -> 2976300167152 [dir=none]
	2976300167152 [label="input
 (1, 3, 400, 400)" fillcolor=orange]
	2976300652080 -> 2976276209808 [dir=none]
	2976276209808 [label="weight
 (64, 3, 7, 7)" fillcolor=orange]
	2976300652080 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (3, 3)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	2976300652272 -> 2976300652080
	2976276209808 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2976276209808 -> 2976300652272
	2976300652272 [label=AccumulateGrad]
	2976300652032 -> 2976300651984
	2976276209904 [label="bn1.weight
 (64)" fillcolor=lightblue]
	2976276209904 -> 2976300652032
	2976300652032 [label=AccumulateGrad]
	2976300651696 -> 2976300651984
	2976276210000 [label="bn1.bias
 (64)" fillcolor=lightblue]
	2976276210000 -> 2976300651696
	2976300651696 [label=AccumulateGrad]
	2976300651792 -> 2976300651600
	2976276210384 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2976276210384 -> 2976300651792
	2976300651792 [label=AccumulateGrad]
	2976300651552 -> 2976300651504
	2976276210480 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2976276210480 -> 2976300651552
	2976300651552 [label=AccumulateGrad]
	2976300651408 -> 2976300651504
	2976276210576 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2976276210576 -> 2976300651408
	2976300651408 [label=AccumulateGrad]
	2976300651312 -> 2976300651168
	2976276210960 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2976276210960 -> 2976300651312
	2976300651312 [label=AccumulateGrad]
	2976300651120 -> 2976300651024
	2976276211056 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2976276211056 -> 2976300651120
	2976300651120 [label=AccumulateGrad]
	2976300651072 -> 2976300651024
	2976276211152 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2976276211152 -> 2976300651072
	2976300651072 [label=AccumulateGrad]
	2976300650976 -> 2976300650928
	2976300650832 -> 2976300650640
	2976276211536 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2976276211536 -> 2976300650832
	2976300650832 [label=AccumulateGrad]
	2976300650592 -> 2976300650544
	2976276211632 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2976276211632 -> 2976300650592
	2976300650592 [label=AccumulateGrad]
	2976300650448 -> 2976300650544
	2976276211728 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2976276211728 -> 2976300650448
	2976300650448 [label=AccumulateGrad]
	2976300650352 -> 2976300650208
	2976276212112 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2976276212112 -> 2976300650352
	2976300650352 [label=AccumulateGrad]
	2976300650160 -> 2976300650064
	2976276212208 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2976276212208 -> 2976300650160
	2976300650160 [label=AccumulateGrad]
	2976300650112 -> 2976300650064
	2976276212304 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2976276212304 -> 2976300650112
	2976300650112 [label=AccumulateGrad]
	2976300650016 -> 2976300649968
	2976300649776 -> 2976300649632
	2976276213264 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2976276213264 -> 2976300649776
	2976300649776 [label=AccumulateGrad]
	2976300649584 -> 2976300649536
	2976276213360 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2976276213360 -> 2976300649584
	2976300649584 [label=AccumulateGrad]
	2976300649440 -> 2976300649536
	2976276213456 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2976276213456 -> 2976300649440
	2976300649440 [label=AccumulateGrad]
	2976300649344 -> 2976300649200
	2976276213840 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2976276213840 -> 2976300649344
	2976300649344 [label=AccumulateGrad]
	2976300649152 -> 2976300649056
	2976276213936 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2976276213936 -> 2976300649152
	2976300649152 [label=AccumulateGrad]
	2976300649104 -> 2976300649056
	2976276214032 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2976276214032 -> 2976300649104
	2976300649104 [label=AccumulateGrad]
	2976300649008 -> 2976300648960
	2976300649008 -> 2976300304048 [dir=none]
	2976300304048 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300649008 -> 2976300718832 [dir=none]
	2976300718832 [label="result1
 (0)" fillcolor=orange]
	2976300649008 -> 2976300719120 [dir=none]
	2976300719120 [label="result2
 (0)" fillcolor=orange]
	2976300649008 -> 2976276212592 [dir=none]
	2976276212592 [label="running_mean
 (128)" fillcolor=orange]
	2976300649008 -> 2976276212976 [dir=none]
	2976276212976 [label="running_var
 (128)" fillcolor=orange]
	2976300649008 -> 2976276212784 [dir=none]
	2976276212784 [label="weight
 (128)" fillcolor=orange]
	2976300649008 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300649728 -> 2976300649008
	2976300649728 -> 2976300302608 [dir=none]
	2976300302608 [label="input
 (1, 64, 100, 100)" fillcolor=orange]
	2976300649728 -> 2976276212688 [dir=none]
	2976276212688 [label="weight
 (128, 64, 1, 1)" fillcolor=orange]
	2976300649728 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	2976300649824 -> 2976300649728
	2976300649872 -> 2976300649728
	2976276212688 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2976276212688 -> 2976300649872
	2976300649872 [label=AccumulateGrad]
	2976300649296 -> 2976300649008
	2976276212784 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2976276212784 -> 2976300649296
	2976300649296 [label=AccumulateGrad]
	2976300649248 -> 2976300649008
	2976276212880 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2976276212880 -> 2976300649248
	2976300649248 [label=AccumulateGrad]
	2976300648864 -> 2976300648672
	2976276214416 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2976276214416 -> 2976300648864
	2976300648864 [label=AccumulateGrad]
	2976300648624 -> 2976300648576
	2976276214512 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2976276214512 -> 2976300648624
	2976300648624 [label=AccumulateGrad]
	2976300648480 -> 2976300648576
	2976276214608 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2976276214608 -> 2976300648480
	2976300648480 [label=AccumulateGrad]
	2976300648384 -> 2976300648240
	2976276214992 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2976276214992 -> 2976300648384
	2976300648384 [label=AccumulateGrad]
	2976300648192 -> 2976300648096
	2976276215088 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2976276215088 -> 2976300648192
	2976300648192 [label=AccumulateGrad]
	2976300648144 -> 2976300648096
	2976276215184 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2976276215184 -> 2976300648144
	2976300648144 [label=AccumulateGrad]
	2976300648048 -> 2976300648000
	2976300647808 -> 2976300647664
	2976276216144 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2976276216144 -> 2976300647808
	2976300647808 [label=AccumulateGrad]
	2976300647616 -> 2976300647568
	2976276216240 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2976276216240 -> 2976300647616
	2976300647616 [label=AccumulateGrad]
	2976300647472 -> 2976300647568
	2976276216336 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2976276216336 -> 2976300647472
	2976300647472 [label=AccumulateGrad]
	2976300647376 -> 2976300647232
	2976276216720 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2976276216720 -> 2976300647376
	2976300647376 [label=AccumulateGrad]
	2976300647184 -> 2976300647088
	2976276216816 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2976276216816 -> 2976300647184
	2976300647184 [label=AccumulateGrad]
	2976300647136 -> 2976300647088
	2976276216912 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2976276216912 -> 2976300647136
	2976300647136 [label=AccumulateGrad]
	2976300647040 -> 2976300646992
	2976300647040 -> 2976300313840 [dir=none]
	2976300313840 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976300647040 -> 2976300724496 [dir=none]
	2976300724496 [label="result1
 (0)" fillcolor=orange]
	2976300647040 -> 2976300724784 [dir=none]
	2976300724784 [label="result2
 (0)" fillcolor=orange]
	2976300647040 -> 2976276215472 [dir=none]
	2976276215472 [label="running_mean
 (256)" fillcolor=orange]
	2976300647040 -> 2976276215856 [dir=none]
	2976276215856 [label="running_var
 (256)" fillcolor=orange]
	2976300647040 -> 2976276215664 [dir=none]
	2976276215664 [label="weight
 (256)" fillcolor=orange]
	2976300647040 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976300647760 -> 2976300647040
	2976300647760 -> 2976300316624 [dir=none]
	2976300316624 [label="input
 (1, 128, 50, 50)" fillcolor=orange]
	2976300647760 -> 2976276215568 [dir=none]
	2976276215568 [label="weight
 (256, 128, 1, 1)" fillcolor=orange]
	2976300647760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	2976300647856 -> 2976300647760
	2976300647904 -> 2976300647760
	2976276215568 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2976276215568 -> 2976300647904
	2976300647904 [label=AccumulateGrad]
	2976300647328 -> 2976300647040
	2976276215664 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2976276215664 -> 2976300647328
	2976300647328 [label=AccumulateGrad]
	2976300647280 -> 2976300647040
	2976276215760 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2976276215760 -> 2976300647280
	2976300647280 [label=AccumulateGrad]
	2976300646896 -> 2976300646704
	2976276217296 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2976276217296 -> 2976300646896
	2976300646896 [label=AccumulateGrad]
	2976300646656 -> 2976300646608
	2976276217392 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2976276217392 -> 2976300646656
	2976300646656 [label=AccumulateGrad]
	2976300646512 -> 2976300646608
	2976276217488 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2976276217488 -> 2976300646512
	2976300646512 [label=AccumulateGrad]
	2976293699488 -> 2976293699392
	2976276365392 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2976276365392 -> 2976293699488
	2976293699488 [label=AccumulateGrad]
	2976293699344 -> 2976293699248
	2976276365488 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2976276365488 -> 2976293699344
	2976293699344 [label=AccumulateGrad]
	2976293699296 -> 2976293699248
	2976276365584 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2976276365584 -> 2976293699296
	2976293699296 [label=AccumulateGrad]
	2976293699200 -> 2976293699152
	2976293698960 -> 2976293698816
	2976276366544 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2976276366544 -> 2976293698960
	2976293698960 [label=AccumulateGrad]
	2976293698768 -> 2976293698720
	2976276366640 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2976276366640 -> 2976293698768
	2976293698768 [label=AccumulateGrad]
	2976293698624 -> 2976293698720
	2976276366736 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2976276366736 -> 2976293698624
	2976293698624 [label=AccumulateGrad]
	2976293698528 -> 2976293698384
	2976276367120 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2976276367120 -> 2976293698528
	2976293698528 [label=AccumulateGrad]
	2976293698336 -> 2976293698240
	2976276367216 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2976276367216 -> 2976293698336
	2976293698336 [label=AccumulateGrad]
	2976293698288 -> 2976293698240
	2976276367312 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2976276367312 -> 2976293698288
	2976293698288 [label=AccumulateGrad]
	2976293698192 -> 2976293698144
	2976293698192 -> 2976300576944 [dir=none]
	2976300576944 [label="input
 (1, 512, 13, 13)" fillcolor=orange]
	2976293698192 -> 2976300730224 [dir=none]
	2976300730224 [label="result1
 (0)" fillcolor=orange]
	2976293698192 -> 2976300730512 [dir=none]
	2976300730512 [label="result2
 (0)" fillcolor=orange]
	2976293698192 -> 2976276365872 [dir=none]
	2976276365872 [label="running_mean
 (512)" fillcolor=orange]
	2976293698192 -> 2976276366256 [dir=none]
	2976276366256 [label="running_var
 (512)" fillcolor=orange]
	2976293698192 -> 2976276366064 [dir=none]
	2976276366064 [label="weight
 (512)" fillcolor=orange]
	2976293698192 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	2976293698912 -> 2976293698192
	2976293698912 -> 2976300567728 [dir=none]
	2976300567728 [label="input
 (1, 256, 25, 25)" fillcolor=orange]
	2976293698912 -> 2976276365968 [dir=none]
	2976276365968 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	2976293698912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	2976293699008 -> 2976293698912
	2976293699056 -> 2976293698912
	2976276365968 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2976276365968 -> 2976293699056
	2976293699056 [label=AccumulateGrad]
	2976293698480 -> 2976293698192
	2976276366064 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2976276366064 -> 2976293698480
	2976293698480 [label=AccumulateGrad]
	2976293698432 -> 2976293698192
	2976276366160 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2976276366160 -> 2976293698432
	2976293698432 [label=AccumulateGrad]
	2976293698048 -> 2976293697856
	2976276367696 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2976276367696 -> 2976293698048
	2976293698048 [label=AccumulateGrad]
	2976293697808 -> 2976293697760
	2976276367792 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2976276367792 -> 2976293697808
	2976293697808 [label=AccumulateGrad]
	2976293697664 -> 2976293697760
	2976276367888 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2976276367888 -> 2976293697664
	2976293697664 [label=AccumulateGrad]
	2976293697568 -> 2976293697424
	2976276368272 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2976276368272 -> 2976293697568
	2976293697568 [label=AccumulateGrad]
	2976293697376 -> 2976293697136
	2976276368368 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2976276368368 -> 2976293697376
	2976293697376 [label=AccumulateGrad]
	2976293697328 -> 2976293697136
	2976276368464 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2976276368464 -> 2976293697328
	2976293697328 [label=AccumulateGrad]
	2976293697040 -> 2976293697088
	2976293696656 -> 2976293696464
	2976293696656 [label=TBackward0]
	2976293697184 -> 2976293696656
	2976276381328 [label="fc.weight
 (5, 512)" fillcolor=lightblue]
	2976276381328 -> 2976293697184
	2976293697184 [label=AccumulateGrad]
	2976293696464 -> 2976300570512
}
